{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we will map fMRI data to a hippocampal surface, and then visualize it\n",
    "\n",
    "We will assume:\n",
    "- HippUnfold was run on the native T1w image from the `ds002168` dataset\n",
    "- fMRI data is already preprocessed and registered to T1w space (eg. via fMRIprep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a test subject\n",
    "\n",
    "func_dir = './ds002168'\n",
    "hippunfold_dir = './ds002168_hippunfold/hippunfold'\n",
    "\n",
    "subject = '1425'\n",
    "hemi = ['L','R']\n",
    "label = ['hipp','dentate'] #the dentate gyrus is given a separate surface from the rest of the hippocampus. Here we will include it but this is optional.\n",
    "\n",
    "!mkdir -p tmp # make a temporary directory for storing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Sample data along a hippocampal surface:\n",
    "\n",
    "NOTE this assumes we have a few tools (`wb_command`) already installed and in out `PATH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we have and understand wb_command:\n",
    "\n",
    "!wb_command -volume-to-surface-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling density\n",
    "\n",
    "For fMRI data, resolution is typically >=2mm, and so I recommend using `den-2mm` surfaces (obtained by adding the flag `--output_density 2mm ` when executing HippUnfold). \n",
    "\n",
    "Otherwise the default `den-0p5mm` surfaces will work fine, but you may be unnecessarily oversampling the fMRI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can construct our call to wb_command, looping over hemispheres and surface label files\n",
    "\n",
    "for h in range(len(hemi)):\n",
    "    for l in range(len(label)):\n",
    "        cmd = f'wb_command -volume-to-surface-mapping '\\\n",
    "            f'{func_dir}/sub-{subject}/func/sub-{subject}_space-T1w_task-mst_run-1_bold.nii.gz '\\\n",
    "            f'{hippunfold_dir}/sub-{subject}/surf/sub-{subject}_hemi-{hemi[h]}_space-T1w_den-2mm_label-{label[l]}_midthickness.surf.gii '\\\n",
    "            f'tmp/sub-{subject}_hemi-{hemi[h]}_space-T1w_den-2mm_label-{label[l]}_task-mst_run-1_bold.func.gii '\\\n",
    "            f'-enclosing'\n",
    "        !echo {cmd}\n",
    "        !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) (optional) Smooth data along hippocampal surface:\n",
    "\n",
    "Most of the time fMRI data benefits from smoothing. This is best done along a surface so values are not combined across a suclus (or across hippocampal folds).\n",
    "\n",
    "Note that depending on your data resolution you may want to adjust the size of the smoothing kernel, but remember that the hippocampus is only ~10mm wide in some regions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 2 #Gaussian smoothing kernal sigma (mm)\n",
    "\n",
    "for h in range(len(hemi)):\n",
    "    for l in range(len(label)):\n",
    "        cmd = f'wb_command -metric-smoothing '\\\n",
    "            f'{hippunfold_dir}/sub-{subject}/surf/sub-{subject}_hemi-{hemi[h]}_space-T1w_den-2mm_label-{label[l]}_midthickness.surf.gii '\\\n",
    "            f'tmp/sub-{subject}_hemi-{hemi[h]}_space-T1w_den-2mm_label-{label[l]}_task-mst_run-1_bold.func.gii '\\\n",
    "            f'{sigma} '\\\n",
    "            f'tmp/sub-{subject}_hemi-{hemi[h]}_space-T1w_den-2mm_label-{label[l]}_task-mst_run-1_bold_smooth-{sigma}mm.func.gii'\n",
    "        !echo {cmd}\n",
    "        !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Load and understand surface data\n",
    "\n",
    "Here, we will only load one hemisphere and one surface (ie. no dentate gyrus). \n",
    "\n",
    "This is to showcase some of the plotting tools in the `HippUnfold_toolbox` and to illustrate how surface data is formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import sys\n",
    "sys.path.insert(1, '/data/mica3/opt/hippunfold_toolbox')\n",
    "from hippunfold_toolbox import plotting\n",
    "np.set_printoptions(threshold=10)\n",
    "\n",
    "\n",
    "surface = nib.load(f'{hippunfold_dir}/sub-{subject}/surf/sub-{subject}_hemi-R_space-T1w_den-2mm_label-hipp_midthickness.surf.gii')\n",
    "func = nib.load(f'tmp/sub-{subject}_hemi-R_space-T1w_den-2mm_label-hipp_task-mst_run-1_bold_smooth-{sigma}mm.func.gii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at how \"metric\" data is formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(func.darrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.darrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.darrays[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.darrays[0].data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at how \"surface\" data is formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface.get_arrays_from_intent('NIFTI_INTENT_POINTSET')[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "plt.scatter(surface.get_arrays_from_intent('NIFTI_INTENT_POINTSET')[0].data[:,0],\n",
    "           surface.get_arrays_from_intent('NIFTI_INTENT_POINTSET')[0].data[:,1],\n",
    "           surface.get_arrays_from_intent('NIFTI_INTENT_POINTSET')[0].data[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface.get_arrays_from_intent('NIFTI_INTENT_TRIANGLE')[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's use a HippUnfold_toolbox function to make plotting easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only the very first timepoint\n",
    "\n",
    "fig,ax = plotting.plot_gifti(surface,func.darrays[0].data)\n",
    "ax.view_init(elev=90, azim=-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also plot on an unfolded surface\n",
    "\n",
    "surface_unfolded = nib.load(f'{hippunfold_dir}/sub-{subject}/surf/sub-{subject}_hemi-L_space-unfolded_den-2mm_label-hipp_midthickness.surf.gii')\n",
    "fig,ax = plotting.plot_gifti(surface_unfolded,func.darrays[0].data)\n",
    "ax.view_init(elev=-90, azim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Make a nice figure with all data\n",
    "\n",
    "This function will use generic surface (ie. not subject-specific) to plot L+R, dentate+hipp, and folded+unfolded surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the hippocampal functional data\n",
    "\n",
    "hipp_func = np.array([])\n",
    "for h in range(len(hemi)):\n",
    "    for l in range(len(label)):\n",
    "        f = nib.load(f'tmp/sub-{subject}_hemi-{hemi[h]}_space-T1w_den-2mm_label-{label[l]}_task-mst_run-1_bold_smooth-{sigma}mm.func.gii')\n",
    "        # format into a Vxt matric (vertices x timepoints)\n",
    "        fvol = np.zeros((len(f.darrays[0].data),len(f.darrays)))\n",
    "        for t in range(len(f.darrays)):\n",
    "            fvol[:,t] = f.darrays[t].data\n",
    "        hipp_func = np.vstack((hipp_func,fvol)) if hipp_func.size else fvol\n",
    "\n",
    "hipp_func.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot (only the first timepoint)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8), subplot_kw={'projection': \"3d\"})\n",
    "plotting.surfplot_canonical_foldunfold(ax, hipp_func[:,0], den='2mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have some fun and turn this data into a gif file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a gif (optional, takes time!)\n",
    "\n",
    "import imageio\n",
    "with imageio.get_writer('tmp/Hippo_ts.gif', mode='I') as writer:\n",
    "    for t in range(hipp_func.shape[1]):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8), subplot_kw={'projection': \"3d\"})\n",
    "        plotting.surfplot_canonical_foldunfold(ax, hipp_func[:,t], den='2mm', cwindow=[150,350])\n",
    "        plt.savefig(f'tmp/frame_{t}.png', dpi=fig.dpi)\n",
    "        image = imageio.imread(f'tmp/frame_{t}.png')\n",
    "        writer.append_data(image)\n",
    "        \n",
    "!rm tmp/frame_*.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling up\n",
    "\n",
    "This code can be looped over all subjects and runs, and can be run on different features. For example, instead of an fMRI image, we could transform and sample a DWI image. \n",
    "\n",
    "All hippunfold subjects have corresponding vertices, meaning that we could load and average across subjects WHERE APPROPRIATE - we wouldn't do this for rsfMRI since subjects may be thinking of different things at different times. We could consider doing this for a time-locked experiment like movie watching, or, we could average across subjects for each vertex for a structural measure like Fractional Anisotropy (FA) derived from DWI. \n",
    "\n",
    "We could consider running an expierment where we compare FA measures across two groups at each vertex. This is more precise than other methods since vertices are carefully aligned between subjects according to their topology in HippUnfold. We could also find the subset of vertices belonging to a given subfield using (for example) the `sub-HC002_hemi-L_space-T1w_den-0p5mm_label-hipp_subfields.label.gii` HippUnfold output file. Averaging data within one of these ROIs may help improve signal-to-noise ratio, at the cost of no longer being able to check for anterior-posterior differences. Alternatively, we could parametrically test whether data aligns with the anterior-posterior axis by correlating it with the unfolded y axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
